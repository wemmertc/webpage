 * {: .ref #cmaj2019}Pelaccia, T., Forestier, G. and Wemmert, C.(2019)  
[**Deconstructing the diagnostic reasoning of human versus artificial intelligence**](https://doi.org/10.1503/cmaj.190506)  
Canadian Medical Association Journal, Vol. 191(48), pp. E1332 - [[Abstract]](javascript: toggleInfos('cmaj2019','abstract')) - [[BibTeX]](javascript: toggleInfos('cmaj2019','bibtex')) - [[PDF]](./publications/cmaj2019.pdf)  
 * {:.bibtex  #cmaj2019_bibtex} ```latex 
@article{pelaccia2019deconstructing,
  title={Deconstructing the diagnostic reasoning of human versus artificial intelligence},
  author={Pelaccia, Thierry and Forestier, Germain and Wemmert, C{\'e}dric},
  journal={CMAJ},
  volume={191},
  number={48},
  pages={E1332--E1335},
  year={2019},
  publisher={Can Med Assoc}
}
```  
 * {:.abstract  #cmaj2019_abstract} 
This article...
 * {: .ref #tmi2018}Grote, A., Schaadt, N., Forestier, G., Wemmert, C. and Feuerhake, F.(2018)  
[**Crowdsourcing of Histological Image Labeling and Object Delineation by Medical Students**](https://doi.org/10.1109/TMI.2018.2883237)  
IEEE Transactions on Medical Imaging, 38(5), 1284-1294 - [[Abstract]](javascript: toggleInfos('tmi2018','abstract')) - [[BibTeX]](javascript: toggleInfos('tmi2018','bibtex')) - [[PDF]](./publications/tmi2018.pdf)  
 * {:.bibtex  #tmi2018_bibtex} ```latex 
@article{grote2018crowdsourcing,
  title={Crowdsourcing of Histological Image Labeling and Object Delineation by Medical Students},
  author={Grote, Anne and Schaadt, Nadine S and Forestier, Germain and Wemmert, C{\'e}dric and Feuerhake, Friedrich},
  journal={IEEE transactions on medical imaging},
  volume={38},
  number={5},
  pages={1284--1294},
  year={2018},
  publisher={IEEE}
}
```  
 * {:.abstract  #tmi2018_abstract} 
Crowdsourcing in pathology has been performed on tasks that are assumed to be manageable by nonexperts. Demand remains high for annotations of more complex elements in digital microscopic images, such as anatomical structures. Therefore, this paper investigates conditions to enable crowdsourced annotations of high-level image objects, a complex task considered to require expert knowledge. Seventy six medical students without specific domain knowledge who voluntarily participated in three experiments solved two relevant annotation tasks on histopathological images: 1) labeling of images showing tissue regions and 2) delineation of morphologically defined image objects. We focus on methods to ensure sufficient annotation quality including several tests on the required number of participants and on the correlation of participants' performance between tasks. In a set up simulating annotation of images with limited ground truth, we validated the feasibility of a confidence score using full ground truth.
For this, we computed a majority vote using weighting factors based on individual assessment of contributors against scattered gold standard annotated by pathologists. In conclusion, we provide guidance for task design and quality control to enable a crowdsourced approach to obtain accurate annotations required in the era of digital pathology.
